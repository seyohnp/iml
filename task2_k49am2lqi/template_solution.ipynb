{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2e81b29c71eb2b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Task 2\n",
    "This serves as a template which will guide you through the implementation of this task. It is advised to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps.\n",
    "This is the jupyter notebook version of the template. For the python file version, please refer to the file `template_solution.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de347e31d213bd5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "First, we import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9e071b8e282a8d6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T18:47:37.485752Z",
     "start_time": "2024-03-10T18:47:37.479263Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, Matern, RationalQuadratic\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "# Add any other imports you need here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f2086e18dd7b5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data Loading\n",
    "TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "(and potentially change initialization of variables to accomodate how you deal with non-numeric data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "402e111cb0d70236",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This loads the training and test data, preprocesses it, removes the NaN\n",
    "values and interpolates the missing data using imputation\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Compute\n",
    "----------\n",
    "X_train: matrix of floats, training input with features\n",
    "y_train: array of floats, training output with labels\n",
    "X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "\"\"\"\n",
    "# Load training data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# print(\"Training data:\")\n",
    "# print(\"Shape:\", train_df.shape)\n",
    "# print(train_df.head(4))\n",
    "# print('\\n')\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# print(\"Test data:\")\n",
    "# print(test_df.shape)\n",
    "# print(test_df.head(2))\n",
    "\n",
    "# Dummy initialization of the X_train, X_test and y_train\n",
    "# TODO: Depending on how you deal with the non-numeric data, you may want to\n",
    "# modify/ignore the initialization of these variables\n",
    "X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "y_train = np.zeros_like(train_df['price_CHF'])\n",
    "X_test = np.zeros_like(test_df)\n",
    "\n",
    "# TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "\n",
    "train_df_CHF = train_df.dropna(subset=['price_CHF']) # Drop all rows with nan entries in \"price_CHF\"\n",
    "\n",
    "X_train = train_df_CHF.drop(columns=['price_CHF', 'season'],axis=1)\n",
    "y_train = train_df_CHF['price_CHF']\n",
    "X_test = test_df.drop(['season'],axis=1)\n",
    "\n",
    "imp_X = IterativeImputer(missing_values=np.nan)\n",
    "imp_X.fit(X_train)\n",
    "\n",
    "X_train = imp_X.transform(X_train)\n",
    "X_test = imp_X.transform(X_test)\n",
    "\n",
    "\n",
    "# spring_df = train_df_CHF[train_df_CHF['season'] == 'spring']\n",
    "# summer_df = train_df_CHF[train_df_CHF['season'] == 'summer']\n",
    "# autumn_df = train_df_CHF[train_df_CHF['season'] == 'autumn']\n",
    "# winter_df = train_df_CHF[train_df_CHF['season'] == 'winter']\n",
    "# #print(winter_df.iloc[:, 1])\n",
    "# #print(np.sum(winter_df.iloc[:, 1]))\n",
    "\n",
    "\n",
    "# seasons_array = [spring_df, summer_df, autumn_df, winter_df]\n",
    "# train_df_filled = pd.DataFrame()\n",
    "\n",
    "# for season_df in seasons_array:\n",
    "#     season_df_filled = pd.DataFrame(np.nan, index=season_df.index, columns=season_df.columns)\n",
    "#     season_df_filled.iloc[0:] = season_df.iloc[0]\n",
    "#     for i in range(1, 11):\n",
    "#         season_col_filled = season_df.iloc[:, i].fillna(np.mean(season_df.iloc[:, i]))\n",
    "#         season_df_filled.iloc[:, i] = season_col_filled\n",
    "\n",
    "#     # Append the filled season dataframe to train_df_filled\n",
    "#     train_df_filled = pd.concat([train_df_filled, season_df_filled], axis=0).sort_index()\n",
    "# #train_df_filled.drop(columns=['season'], inplace=True)\n",
    "\n",
    "# spring_df = test_df[test_df['season'] == 'spring']\n",
    "# summer_df = test_df[test_df['season'] == 'summer']\n",
    "# autumn_df = test_df[test_df['season'] == 'autumn']\n",
    "# winter_df = test_df[test_df['season'] == 'winter']\n",
    "\n",
    "# seasons_array = [spring_df, summer_df, autumn_df, winter_df]\n",
    "# print(seasons_array)\n",
    "# test_df_filled = pd.DataFrame()\n",
    "\n",
    "# for season_df in seasons_array:\n",
    "#     season_df_filled = pd.DataFrame(np.nan, index=season_df.index, columns=season_df.columns)\n",
    "#     season_df_filled.iloc[0:] = season_df.iloc[0]\n",
    "#     for i in range(1, 10):\n",
    "#         season_col_filled = season_df.iloc[:, i].fillna(np.mean(season_df.iloc[:, i]))\n",
    "#         season_df_filled.iloc[:, i] = season_col_filled\n",
    "\n",
    "#     # Append the filled season dataframe to train_df_filled\n",
    "#     test_df_filled = pd.concat([test_df_filled, season_df_filled], axis=0).sort_index()\n",
    "# #train_df_filled.drop(columns=['season'], inplace=True)\n",
    "\n",
    "# \n",
    "# label_encoder = LabelEncoder()\n",
    "# X_train['season'] = label_encoder.fit_transform(X_train['season'])\n",
    "# X_test['season'] = label_encoder.fit_transform(X_test['season'])\n",
    "\n",
    "# X_train = train_df_filled.drop(['price_CHF'],axis=1)\n",
    "# y_train = train_df_filled['price_CHF']\n",
    "# X_test = test_df_filled\n",
    "\n",
    "# print(X_train)\n",
    "# # print(y_train)\n",
    "\n",
    "\n",
    "assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959037466887e870",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Modeling and Prediction\n",
    "TODO: Define the model and fit it using training data. Then, use test data to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9fb0d86b605f9813",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This defines the model, fits training data and then does the prediction\n",
    "with the test data \n",
    "\n",
    "Parameters\n",
    "----------\n",
    "X_train: matrix of floats, training input with 10 features\n",
    "y_train: array of floats, training output\n",
    "X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "Compute\n",
    "----------\n",
    "y_test: array of floats: dim = (100,), predictions on test set\n",
    "\"\"\"\n",
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._x_train = None\n",
    "        self._y_train = None\n",
    "        self.gpr = GaussianProcessRegressor(kernel=RationalQuadratic())\n",
    "\n",
    "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
    "        #TODO: Define the model and fit it using (X_train, y_train)\n",
    "        \n",
    "        self.gpr.fit(X_train, y_train)\n",
    "\n",
    "        self._x_train = X_train\n",
    "        self._y_train = y_train\n",
    "\n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        #TODO: Use the model to make predictions y_pred using test data X_test\n",
    "        y_pred=np.zeros(X_test.shape[0])\n",
    "        y_pred = self.gpr.predict(X_test)\n",
    "        \n",
    "        assert y_pred.shape == (X_test.shape[0],), \"Invalid data shape\"\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "82790069-ee91-4ec5-9dcd-3d40f436367a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "# Use this function for training the model\n",
    "model.train(X_train=X_train, y_train=y_train)\n",
    "# Use this function for inferece\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c62e0cd4cec5a7e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Saving Results\n",
    "You don't have to change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "382d87d2d67ddbdc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results file successfully generated!\n"
     ]
    }
   ],
   "source": [
    "dt = pd.DataFrame(y_pred) \n",
    "dt.columns = ['price_CHF']\n",
    "dt.to_csv('results.csv', index=False)\n",
    "print(\"\\nResults file successfully generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c441b81e-59db-4b12-86a4-731b3f81fd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4gd-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
